{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsinc/daniels.github.io/blob/master/CodeFormer_TICnoticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjdQE0kKcqjA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/14334509/179359809-bd45566a-486d-418f-83fa-67bbbba8c45c.png\" height=200>\n",
        "  <img src=\"https://yt3.googleusercontent.com/NemKmVODnEeVugVNqqTih6ivIOYLvl-TjTHjDTrSjvnZNSDl2dnOdHZLRVWNTXj9Ci0JONlRbvU=s900-c-k-c0x00ffffff-no-rj\" height=200>\n",
        "</p>\n",
        "\n",
        "# Demostraci贸n de inferencia de CodeFormer\n",
        "## Hacia una restauraci贸n robusta de la cara ciega con el transformador de b煤squeda de libros de c贸digos (NeurIPS 2022)\n",
        "Shangchen Zhou, Kelvin C.K. Chan, Chongyi Li, Chen Change Loy\n",
        "\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social)](https://github.com/sczhou/CodeFormer) [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2206.11253) [![Hugging Face](https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue)](https://huggingface.co/spaces/sczhou/CodeFormer) ![visitors](https://visitor-badge.glitch.me/badge?page_id=sczhou/CodeFormer)\n",
        "\n",
        "...\n",
        "\n",
        "## Tutorial de YouTube hecho por TICnoticos\n",
        "https://www.youtube.com/watch?v=GDnfPeFkC6U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5Bu-qie_aH"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 1. Preparaci贸n\n",
        "Antes de comenzar, aseg煤rese de elegir\n",
        "\n",
        "* Acelerador de hardware = GPU (en el men煤 Tiempo de ejecuci贸n -> Cambiar tipo de tiempo de ejecuci贸n).\n",
        "\n",
        "A continuaci贸n, clonamos el repositorio, configuramos el entorno y descargamos el modelo previamente entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SG9AcLQO_FQ"
      },
      "outputs": [],
      "source": [
        "# Clone CodeFormer and enter the CodeFormer folder\n",
        "%cd /content\n",
        "!rm -rf CodeFormer\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "%cd CodeFormer\n",
        "\n",
        "# Set up the environment\n",
        "# Install python dependencies\n",
        "!pip install -r requirements.txt\n",
        "# Install basicsr\n",
        "!python basicsr/setup.py develop\n",
        "\n",
        "# Download the pre-trained model\n",
        "!python scripts/download_pretrained_models.py facelib\n",
        "!python scripts/download_pretrained_models.py CodeFormer\n",
        "\n",
        "# Visualization function\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzLAguVdix6_"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 2. Prueba tus imagenes/fotos \n",
        "\n",
        "*   Imagenes/Fotografias antiguas\n",
        "*   Imagenes/Fotografias borrosas\n",
        "*   Imagenes/Fotografias desenfocadas\n",
        "*   Imagenes/Fotografias con ruido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK3esrSmiziX"
      },
      "outputs": [],
      "source": [
        "# Sube tus propias imagenes\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_folder = 'inputs/user_upload'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'move {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj2YQGg3J0TQ"
      },
      "outputs": [],
      "source": [
        "CODEFORMER_FIDELITY = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "# @markdown `BACKGROUND_ENHANCE`: Mejorar la imagen de fondo con Real-ESRGAN<br>\n",
        "BACKGROUND_ENHANCE = True #@param {type:\"boolean\"}\n",
        "# @markdown `FACE_UPSAMPLE`: Muestreo adicional de rostros restaurados para im谩genes de alta resoluci贸n creadas por IA<br>\n",
        "FACE_UPSAMPLE = True #@param {type:\"boolean\"}\n",
        "if BACKGROUND_ENHANCE:\n",
        "  if FACE_UPSAMPLE:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan --face_upsample\n",
        "  else:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan\n",
        "else:\n",
        "  !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4hauJLwIQQV"
      },
      "outputs": [],
      "source": [
        "# Visualizar resultados (preview)\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/user_upload'\n",
        "result_folder = f'results/user_upload_{CODEFORMER_FIDELITY}/final_results'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "for input_path in input_list:\n",
        "  img_input = imread(input_path)\n",
        "  basename = os.path.splitext(os.path.basename(input_path))[0]\n",
        "  output_path = os.path.join(result_folder, basename+'.png')\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar resultados\n",
        "!ls results\n",
        "os.system(f'zip -r results.zip results/user_upload_{CODEFORMER_FIDELITY}/final_results')\n",
        "files.download(\"results.zip\")"
      ],
      "metadata": {
        "id": "0RRKl1iDMpVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_U5Bu-qie_aH"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}